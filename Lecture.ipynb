{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# R Basics - Statistical Data Analysis\n",
    "by Dr. Matthias Duschl & Dr. Daniel Lee, 2020\n",
    "\n",
    "## Schedule\n",
    "### Day 1\n",
    "* The R environment - working with the command line\n",
    "* A practical example\n",
    "* Introducing the data sets\n",
    "* How to load data into R\n",
    "* Objects in R\n",
    "* Visualization Part 1\n",
    "\n",
    "### Day 2\n",
    "* Statistics in R: distribution tests\n",
    "* Statistics in R: statistical modelling\n",
    "* Data structures and preparation for analyses\n",
    "* Programming in R\n",
    "* Visualization Part 2 (ggplot)\n",
    "* Reproducible research in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on the command line\n",
    "\n",
    "R can be used as a calculator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "1 + 3  # Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8 %% 3  # Remainder division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5 ^ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every expression you run produces a result. If you don't \"capture\" it by saving it to a variable, it is reported back on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1:10  # Generate a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(1:10)  # Use a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- mean(1:10) # Capture results by saving it to a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following syntax is typical:\n",
    "\n",
    "```\n",
    "output <- function(data, parameters)\n",
    "?function  # displays help\n",
    "```\n",
    "\n",
    "### Inspecting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- c(5,4,1,6,3,1,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?c  # Get description for function c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntax - and syntax errors\n",
    "R is a programming environment - that means it's not smart.\n",
    "If you enter the name of a function or object and you mistype a letter, R won't find what you're looking for.\n",
    "Also, remember that R is case-sensitive.\n",
    "Furthermore, if you make a \"syntax error\" - for example calling a function without the right number of arguments, or forgetting to close parentheses - R will not guess what you meant.\n",
    "It will display an error.\n",
    "\n",
    "However, if you're typing and you make a mistake, don't worry that much - you can always go back and try it again.\n",
    "And if you forget to close parentheses but everything else is fine, just close them on the next line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean(x)  # Produces an error because it's called \"mean\", not \"Mean\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(x\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Golden rule: Use the arrow keys to scroll through the history of RStudio\n",
    "\n",
    "Trick: When using RStudio, write your commands into the script, rather than the terminal, then run them with `Ctrl+Enter` so you always have a record of what you did and can correct things if you need to.\n",
    "\n",
    "### Getting help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?read.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different kinds of arguments associated with a function:\n",
    "* positional arguments, which are necessary\n",
    "* named arguments, which are optional and come with a default value after the `=` in the documentation\n",
    "* `...` (ellipsis), which contain further arguments not described here (they are \"inherited\" from other classes - more on that later!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A practical example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and inspect the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims <- read.table(\"data/Auto_Insurance_Claims_Sample.csv\", sep=\",\", header=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(claims$Claim.Amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare and manipulate the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(claims$Education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims$Education.Level <- \"low\"\n",
    "claims$Education.Level[claims$Education %in% c(\"Master\", \"Doctor\", \"Bachelor\")] <- \"high\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_basic <- claims[claims$Coverage == \"Basic\", ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a statistical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_claims <- glm(Claim.Amount ~ Monthly.Premium.Auto + Income + Education.Level + Claim.Reason,\n",
    "                  data=claims_basic, family=Gamma(link='log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(fit_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(fit_claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a publication-quality visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a library that contains functions we want to use\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p <- ggplot(claims,\n",
    "       aes(x=Monthly.Premium.Auto, y=Claim.Amount, color=Coverage))\n",
    "p + geom_point(size=0.5,alpha=0.3) + facet_wrap(~Coverage) +\n",
    "    geom_smooth(method=\"lm\", color=\"orange\", linetype=2) +\n",
    "    labs(title=\"Claim Analyses\", x=\"Monthly Premium\", y=\"Claim Amount\") +\n",
    "    scale_colour_brewer(palette = \"Set1\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing the data sets\n",
    "\n",
    "We use two main data sets for this training.\n",
    "\n",
    "#### Aphasia\n",
    "The Aphasia data contains experimental data from 36 patient. It contains general information on the patient (e.g. type of Aphasia, gender) as well as measurements from the neurolinguistic experiments (e.g. lexical decision time). It was cordially provided to us from the neurolinguistic institute of the University of Marburg.\n",
    "\n",
    "#### Auto Insurance Claims\n",
    "The Auto Insurance Claims data represents a publically available sample data set from motor insurance claims. Each line represents a claim. Besides to some information on the claim (e.g. Claim Amount), additional information on the customer, policy and coverage is available for each claim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to load data into R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The working directory\n",
    "\n",
    "R always works in a given folder. If you read from or write to any files, you must either specify their absolute path or a relative path. Relative paths are relative to the current working directory. Often, you can save a lot of typing by navigating into a working directory and using relative paths from there.\n",
    "\n",
    "If you are working in a Notebook, the working directory is the directory that the Notebook is stored in by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getwd()  # Find out current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path where the data is stored on your computer. Some examples:\n",
    "#work.dir <- \"D:/BEN/my_name\"\n",
    "#work.dir <- \"~/Dropbox/Bio-Workshop\"\n",
    "work.dir <- \"C:/Users/n351384/OneDrive - Munich Re/Privat/R basics 2days\"\n",
    "# Set this to directory with your data\n",
    "setwd(work.dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading tables\n",
    "\n",
    "When you read a table from a file stored on disk, the path to that file is relative to the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?read.table  # overview on all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims <- read.table(\"data/Auto_Insurance_Claims_Sample.csv\", sep=\",\", header=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If ``header=TRUE`` column names will always be taken from first row of the file.\n",
    "\n",
    "The parameter ``header`` is automatically ``TRUE`` if first row is shorter (by one) than all other rows.\n",
    "Otherwise ``header`` is set to ``FALSE``.\n",
    "\n",
    "Therefore: ``header=TRUE`` is necessary if the field on the top left of the table is not empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aphasiker <- read.table(\"data/aphasiker.csv\", sep=\";\", dec=\",\", header=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The most common errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read.table(\"data/Aphasiker.csv\", sep=\";\", dec=\",\", header=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Are there any typos? (case-sensitive!)\n",
    "* Did you forget the file extension?\n",
    "* Did you specify the right path relative to your working directory? Check again with ``getwd()`` and ``dir()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read.table(\"data/aphasiker.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Did you specify the column separator (and decimal character)?\n",
    "* Is there a header row in the file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pro tip: Use RStudio \"Import Dataset\" for importing a new data set the first time\n",
    "The code for reading the data in will appear in the console. You can copy and paste to your script to read the data quickly in your next R session.\n",
    "\n",
    "The [official R handbook](https://cran.r-project.org/doc/manuals/r-release/R-data.html) describes how to load data from other types of data sources.\n",
    "\n",
    "Moreover, there are plenty of packages to read from Excel files (``readxl``), larger data sets (``data.table``), databases (``dplyr``) or shapefiles (``sf``).\n",
    "\n",
    "Regarding Excel: many people prefer to export Excel files as CSV files and import them in the standard way instead of directly establishing a connection to the Excel file for reading its data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(claims)  # get only first rows of table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail(claims)  # get only last rows of table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(claims)  # how many rows does the table have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(claims)  # what are the column names of the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(claims)  # a quick summary of the table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(claims)  # deeper information on the table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: examine the Aphasiker data set\n",
    "\n",
    "Learn about the data by applying the functions from above to the Aphasiker data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objects in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types\n",
    "There are different data types. The most important are:\n",
    "* Numeric\n",
    "* Character\n",
    "* Logical\n",
    "\n",
    "Incompatible types can't be used together in ways R won't expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0  # Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"zero\"  # Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FALSE  # Logical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"a string\" + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other data types as well, and if you get really advanced you can even define your own.\n",
    "This won't be covered in this basic class, though.\n",
    "\n",
    "Try it out on your own by doing exercise 2!\n",
    "\n",
    "#### Vectors\n",
    "Vectors are collections of elements with the same type.\n",
    "Elements are combined using the ``c`` function, which stands for \"concatenate\" or \"combine\".\n",
    "\n",
    "Here we save a numeric vector to the variable ``numbers``. The result of a variable name is its value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers <- c(5, 79, 234, 150, 0, -986)\n",
    "numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access individual elements of a vector by index number.\n",
    "R starts counting at 1, so this will return element 1 of ``numbers``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the index negative negates the query, so that all elements *except* the\n",
    "named position are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers[-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify a range of index positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For higher granularity, provide a vector of precisely the positions you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers[c(1:3, 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors with the same type can be concatenated to produce a new vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers2 <- -2:-10\n",
    "new.numbers <- c(numbers, numbers2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the same goes for a vector of characters or logical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some.strings <- c(\"This\", \"is\", \"a\", \"bunch\", \"of\", \"strings\")\n",
    "some.strings[2:4]\n",
    "some.strings[-(2:4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In R, every data type is, in the end, a vector.\n",
    "Single elements of a vector are not special in any way; they are simply vectors with a length of 1.\n",
    "When you apply an operation across vectors, it is done piece by piece, across each element of both vectors.\n",
    "If a vector isn't long enough to allow this, it gets \"unwrapped\" - its length is extended until it is long enough to do the operation the \"usual way\".\n",
    "R will warn you if it can't do this cleanly, i.e. if the lengths aren't compatible.\n",
    "\n",
    "Try it out in exercise 3.\n",
    "\n",
    "#### Functions\n",
    "Functions are collections of instructions. \n",
    "They keep you from having to repeat the same statements again and again. \n",
    "They can be saved to named variables like any other value. \n",
    "They are called by using the call operator ``()`` containing any arguments the function requires.\n",
    "The arguments are used inside the function, so that its results depend on the data passed to it.\n",
    "\n",
    "For information on any function, use the ``?`` operator.\n",
    "You'll be shown a description of the function.\n",
    "There are many standard functions that you can use, and if you like you can even write your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?mean  # How do I use the function \"mean\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(numbers)  # Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(numbers)  # Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var(numbers)  # Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NAs\n",
    "``NA`` stands for \"not available\" and is used in R to signify a missing value.\n",
    "The value ``NA`` can be coerced to any type and can't produce a non-``NA`` value in expressions.\n",
    "\n",
    "``NA``s are often used to stand for values that can't be computed or are not present in input data.\n",
    "\n",
    "``NA``s can be created as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not.available <- NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that ``NA``s propogate when used in expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(c(numbers, not.available))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often you can instruct functions to remove them by setting the argument\n",
    "```\n",
    "na.rm = TRUE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(c(numbers, not.available), na.rm = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(numbers)\n",
    "sort(numbers, decreasing = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to replace the old vector with its sorted version, overwrite it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers <- sort(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering uses expressions that produce logical vectors to tell R which values from a vector to keep and which to throw away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers[numbers < 100]\n",
    "numbers[numbers > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logical statements can be combined with ``&`` for \"and\" and ``|`` for \"or\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers[numbers < 100 & numbers > 0]\n",
    "numbers[numbers > 100 | numbers < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out the length of a vector with ``length``.\n",
    "\n",
    "Here we use that to count the number of even values in ``numbers``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(numbers[numbers %% 2 == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random numbers\n",
    "R has lots of standard functions for random number generation. There are several distribution types you can use - see ``distributions`` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a series of 100 uniformly distributed random numbers in the range from -500 to 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.numbers <- runif(min = -500, max = 500, n = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: working with random numbers\n",
    "\n",
    "TODO: Move this into the exercise notebook\n",
    "\n",
    "* Generate a series of 100 normally distributed numbers centered at 0 with a standard deviance of 200.\n",
    "* What's their standard deviance? Is it really what you specified?\n",
    "* What's their variance?\n",
    "* Sort them in ascending order.\n",
    "* Sort them in descending order.\n",
    "* Filter out negative values.\n",
    "* Do the exercises again for a series of exponentially distributed values, this time filtering for values under 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data frames\n",
    "A data frame is used for storing tabular data.\n",
    "It is a list of vectors of equal length.\n",
    "For example, the following variable ``df`` is a data frame containing three vectors ``n``, ``s``, ``b``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a <- c(2, 3, 5) \n",
    "b <- c(\"aa\", \"bb\", \"cc\") \n",
    "c <- c(TRUE, FALSE, TRUE) \n",
    "df <- data.frame(a, b, c)  # create new data.frame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class(claims)  # get information on class of object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(claims)  # get single elements/vectors of a data.frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, you don't want to work with all the data in a data frame.\n",
    "R has many efficient ways of filtering out individual columns, rows, values or arbitrary subsections.\n",
    "Here are ways to access a single column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims$Claim.Amount  # By variable name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims[[\"Claim.Amount\"]]  # by name string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims[,5]  # by column number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(claims)  # find the column numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(claims[-5])  # the reverse: all columns except 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``data.frames`` store columns as vectors, so we can pass them to a function without having to preprocess them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(claims$Claim.Amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** You should **NOT** use the ``attach(data.frame)`` function.\n",
    "With ``attach``, all column names will become new variables in the global R namespace.\n",
    "Only do this in interactive mode for data exploration, **never** use it in scripts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attach(claims)\n",
    "mean(Claim.Amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detach(claims)\n",
    "mean(Claim.Amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, you can access any value you want with coordinates like that. The notation is ``[ ROW-id , COLUMN-id ]``.\n",
    "If you leave out a dimension it gives you all values along that coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims[42,]  # Row 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims[37, 8]  # Row 37, column 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same notation allows to filter the data using logical statements.\n",
    "Actually, the logical statements give us a boolean vector which is used to filter the ``data.frame`` row-wise, returning only the values whose corresponding value in the boolean vector are ``TRUE``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims[claims$State == \"Kansas\" & claims$Months.Since.Policy.Inception <= 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims$State == \"Kansas\" & claims$Months.Since.Policy.Inception <= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the data.frame can be filtered using a function called ``subset()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset(aphasiker, State == \"Kansas\" & Months.Since.Policy.Inception <= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding data to data frames\n",
    "In order to add a column to a data frame, just write to it as it were already there, using any of the ways of accessing data frames listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims$id <- 1:nrow(claims)  # Assign an ID number to each row\n",
    "head(claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example for re-classifying data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims$Large.Loss <- \"No\"\n",
    "claims$Large.Loss[claims$Claim.Amount > 1000] <- \"Yes\"\n",
    "table(claims$Large.Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: working with ``data.frames``\n",
    "\n",
    "Answer the following questions using the aphasiker data:\n",
    "- How many patients are in the data?\n",
    "- What is the average age of the patients?\n",
    "- How many women are among the patients? (Make a frequency table)\n",
    "\n",
    "Answer the following questions using the claims file:\n",
    "- What is the mean, median, minimum and maximum of the Total Claim Amount?\n",
    "- What is the average Total Claim Amount for highly-qualified (Doctor and Master) versus the other insured?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ``apply()`` function\n",
    "The ``apply`` family of functions allow us to repeat actions for several objects, e.g. across all rows or columns of a data frame.\n",
    "\n",
    "The help tells us that we tell ``apply`` to do the same thing either for all rows or for all columns of a table-like structure. The arguments are passed like this:\n",
    "\n",
    "```\n",
    "apply(data, number for row or column, function, other arguments)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(aphasiker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "apply(aphasiker, 2, summary)  # Apply \"summary\" to each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(aphasiker)  # For comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``apply`` tries to coerce data to having the same type.\n",
    "In this example, the common data type is \"character\".\n",
    "This doesn't always make sense.\n",
    "We can prevent this from happening by removing the non-number columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply(aphasiker[, c(3,4, 6:14)], 2, mean, na.rm=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing files\n",
    "Like ``read.table()``, you can use ``write.table()`` to store the objects like a ``data.frame`` permanently on your disk.\n",
    "Remember: filenames are relative to the current working directory or they have to be absolute paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.table(claims, \"claims_new.txt\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(object.name, \"claims_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?write.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Part 1\n",
    "R has several plotting systems. The default plotting system is good for rapid data exploration, because the syntax for basic plots like histograms is very simple.<br>\n",
    "However, the plots usually do not have publication quality and for more complex, multi-dimensional visualizations the code becomes quite complex. There are further plotting systems like ggplot2 which we will explore in Part II. \n",
    "\n",
    "This is the basic principle for creating \"standard\" plots:\n",
    "* First, create a **high-level plot** using plot(), hist(), barplot() ...\n",
    "* Then, you might add some further **low-level elements** to the plot\n",
    "* Both high-level and low-level plots can be customized by setting further graphical parameters. See http://www.statmethods.net/advgraphs/parameters.html or enter the following for getting help on the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first approach for data analysis is to study the distributions of the\n",
    "variables. Therefore, we can draw a histogram of one of our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(claims$Claim.Amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks a bit skewed. We can also change the number of bars and make the plot more appealing by setting the color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(claims$Claim.Amount, breaks=20, col=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to specify the color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(claims$Claim.Amount, breaks=20, col=3)\n",
    "hist(claims$Claim.Amount, breaks=20, col=\"#31a354\")\n",
    "hist(claims$Claim.Amount, breaks=20,\n",
    "     col=rgb(117, 107, 177, maxColorValue = 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change the title and axes labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(claims$Claim.Amount, breaks=20, col=\"#31a354\", \n",
    "     main=\"Histogram\",\n",
    "     xlab=\"Claims Amount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further **low-level graphics** can be added. Low-level graphics, like lines or rugs, are added by calling the correspondung function after plotting the high-level graphic.<br>\n",
    "Also low-level graphics can be customized using paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(claims$Claim.Amount, breaks=20, col=\"#31a354\", \n",
    "     main=\"Histogram\",\n",
    "     xlab=\"Claims Amount\")\n",
    "abline(v = mean(claims$Claim.Amount, na.rm=T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(claims$Claim.Amount, breaks=20, col=\"#31a354\", \n",
    "     main=\"Histogram\",\n",
    "     xlab=\"Claims Amount\")\n",
    "abline(v = mean(claims$Claim.Amount, na.rm=T), col = \"red\", lwd = 2)\n",
    "abline(v = median(claims$Claim.Amount, na.rm=T), col = \"blue\", lwd = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(claims$Claim.Amount, breaks=20, col=\"#31a354\", \n",
    "     main=\"Histogram\",\n",
    "     xlab=\"Claims Amount\")\n",
    "rug(claims$Claim.Amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a density plot with a density line, the y-axis needs to be changed to relative frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(claims$Claim.Amount, freq=F, breaks=20, col=\"#31a354\", \n",
    "     main=\"Histogram\",\n",
    "     xlab=\"Claims Amount\")\n",
    "lines(density(claims$Claim.Amount), lwd=2, col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving plots\n",
    "Finally, to save the graphic, use the export functions in RStudio. As a command-line alternative (which works in RStudio or Jupyter), write the current \"device\" directly to an image file such as png or pdf. You also can specify the resolution with width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(claims$Claim.Amount, breaks=20, col=\"#31a354\", \n",
    "     main=\"Histogram\",\n",
    "     xlab=\"Claims Amount\")\n",
    "dev.copy2pdf(file = \"histogram.pdf\", width = 7, height = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise: Visualize it!</span>\n",
    "Use the claims data and explore the distribution of the variables visually. For instance,\n",
    "* create a histogram for show the Income distribution of the customers. Are the values you might want to filter out? \n",
    "* a barplot for state, education or claim reason. For this, you need to count the frequencies first using **table()**<br>\n",
    "Try to customize your plots using colors and axes labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting frequencies for categorical variables\n",
    "In this dataset, we find some categorial variables, like the type of \"Aphasie\" or  gender. For this type of variables, **barplots** are good visualization. PlotPlotting the frequency requires to count the occurences for each category first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender.table <- table(aphasiker$Geschlecht)\n",
    "barplot(gender.table, col=rainbow(2), main=\"Gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, pie charts are proposed as an alternative to barcharts. See the help file (?pie) to read what R users think about pie charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie(gender.table) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions of age across different types of Aphasie can be compared using box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(aphasiker$Alter ~ aphasiker$Aphasie, col=\"gold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-variate plots \n",
    "Often, we want to study differences and relationships between more than one variable, for instance, between \"Claims Amount\" and\n",
    "\"Total Claims Amount\" of an insured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(claims$Total.Claim.Amount, claims$Claim.Amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise: Regression lines</span>\n",
    "Use the claims data and visualize the relationship between \"Claims Amount\" and \"Total Claims Amount\". \n",
    "\n",
    "Try to customize your scatterplot:\n",
    "* Choose a color for the dots and a different symbol with the parameter pch\n",
    "* Control the size of the symbols (?par shows you an overview on all graphical parameters)\n",
    "* Add a linear regression line using **abline()** and the coefficients from a linear model lm(): **abline(lm(var1 ~ var2))**<br>Which one is the dependent variable in the model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line charts\n",
    "A line chart is essentially a scatterplot in which the dots are connected. To produce a line chart from the scratch, apply the following steps:\n",
    "* First, set the index variable at the x-axis \n",
    "* Next,  define the values at the y-axis \n",
    "* Finally, we draw a line through the points, resulting in a trend line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- 2001:2010\n",
    "y <- c(4,1,6,3,8,5,4,7,3,9)\n",
    "plot(x, y, type=\"l\", lwd=2, col=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heat maps\n",
    "Even with the default plotting system, some \"advanced graphics\" can be created. Let's open the documentation for heatmaps and replicate the given example at the end of the documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x  <- as.matrix(mtcars)\n",
    "rc <- rainbow(nrow(x), start = 0, end = .3)\n",
    "cc <- rainbow(ncol(x), start = 0, end = .3)\n",
    "hv <- heatmap(x, col = cm.colors(256), scale = \"column\",\n",
    "              RowSideColors = rc, ColSideColors = cc, margins = c(5,10),\n",
    "              xlab = \"specification variables\", ylab =  \"Car Models\",\n",
    "              main = \"heatmap(<Mtcars data>, ..., scale = \\\"column\\\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics in R: distribution tests\n",
    "\n",
    "In the following sections we will explore how to perform statistical tests and how to build more advanced statistical models. First, we are going to test the frequency distributions. Second, we will compare (the mean value of) two samples. Finally, we are building multi-variate models, namely ANOVA models and linear regression models. Of course, we are also concerned with checking the assumptions of these models as well as bringing the data into the right shape.\n",
    "\n",
    "The most common statistical tests and models come with the base distribution of R \n",
    "* t.test()\n",
    "* wilcox.test()\n",
    "* chisq.test()\n",
    "* ks.test()\n",
    "* cor.test()\n",
    "* anova()\n",
    "* lm()\n",
    "\n",
    "… and many, many more!<br>\n",
    "You find an overview on extension packages for more advanced methods here: http://cran.r-project.org/web/views/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aphasiker <- read.table(\"Aphasiker.csv\", sep=\";\", dec=\",\", header=TRUE)\n",
    "claims <- read.table(\"data/Auto_Insurance_Claims_Sample.csv\", sep=\",\", header=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chi-squared test\n",
    "First, we want to test if we have an equal distribution of gender in our sample data set.<br>\n",
    "* Using the table() function, we simply count the gender occurences.\n",
    "* Raw frequencies can also be converted to fractions using prop.table()\n",
    "\n",
    "The chi-squared test against a uniform distribution is finally used to test the null hypothesis that male and female aphasiker are equally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(aphasiker$Geschlecht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop.table(table(aphasiker$Geschlecht))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq.test(table(aphasiker$Geschlecht))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can also be stored in a new object. Such kind of \"model objects\" are usually a list containing many detailed information, like the expected value for the tested dstribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_gender <- chisq.test(table(aphasiker$Geschlecht))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(chi_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_gender$expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected distribution to test against can be modified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq.test(table(aphasiker$Geschlecht), p=c(0.3,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, the chi-squared test is mainly used to compare two empirical frequency distributions. For this, we need to create a contingency table object from our data and use this as input for the chi-squared test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_Gender_Aphasie <- table(aphasiker$Geschlecht, aphasiker$Aphasie)\n",
    "table_Gender_Aphasie\n",
    "chisq.test(table_Gender_Aphasie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warnings often provide helpful information. Here we might consider the alternative Fisher test for exact p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher.test(table_Gender_Aphasie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have learnt that the some function can take different data formats. For the chisq.test, we can also create a matrix from the scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_Gender_Aphasie <- matrix(c(3,4,4,5,6,5,5,4), nrow=2, byrow=T)\n",
    "matrix_Gender_Aphasie\n",
    "chisq.test(matrix_Gender_Aphasie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution tests\n",
    "A different approach is to test if your data is in accordance with a theoretical distribution. This kind of tests are often useful to confirm that model assumptions are fulfilled. Examples are:\n",
    "* The Shapiro test for normality\n",
    "* The Kolmogorov Smirnov test as a more general test, in which you can specify (any!) continuous distribution\n",
    "\n",
    "Can you explain the large difference in the p-values between Shapiro and KS-test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro.test(aphasiker$Lex_Dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks.test(aphasiker$Lex_Dec, \"pnorm\", mean=mean(aphasiker$Lex_Dec, na.rm=T),\n",
    "         sd=sd(aphasiker$Lex_Dec, na.rm=T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have to handle NA values appropriately! Alternatively, you could remove all NAs from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(aphasiker$Lex_Dec)\n",
    "mean(aphasiker$Lex_Dec, na.rm=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lex_Dec_new <- na.omit(aphasiker$Lex_Dec)\n",
    "ks.test(Lex_Dec_new, \"pnorm\", mean=mean(Lex_Dec_new), sd=sd(Lex_Dec_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also plot the distribution:\n",
    "* First, we create a histogram using densities on the y-axis\n",
    "* Then, we add a kernel line of densities\n",
    "* Finally, we add a theoretical distribution, which we specifiy with empirical paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(aphasiker$Lex_Dec, freq=F)\n",
    "lines(density(aphasiker$Lex_Dec, na.rm=T))\n",
    "curve(dnorm(x, mean=mean(aphasiker$Lex_Dec, na.rm=T), sd=sd(aphasiker$Lex_Dec, na.rm=T)),\n",
    "      col=\"darkblue\", lwd=2, add=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test and its variants\n",
    "Do Broca (B) Aphasics show slower RTs in the lexical decision task than Wernicke (W) Aphasics? Here, we need to compare two samples. The most common test it the t-test.\n",
    "\n",
    "First, we subset the two samples from our data. The new data.frame has the some number of columns, but different number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aphasiker_BW <- subset(aphasiker, Aphasie == \"B\" | Aphasie == \"W\")\n",
    "aphasiker_BW <- aphasiker[aphasiker$Aphasie == \"W\" | aphasiker$Aphasie == \"B\", ]\n",
    "dim(aphasiker)\n",
    "dim(aphasiker_BW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test(aphasiker_BW$Lex_Dec ~ aphasiker_BW$Aphasie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using formula notation ~, you can directly compare two columns/vectors. For this, the two variables are separated by a simple comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aphasiker_B <- subset(aphasiker, Aphasie == \"B\")\n",
    "aphasiker_W <- subset(aphasiker, Aphasie == \"W\")\n",
    "t.test(aphasiker_B$Lex_Dec, aphasiker_W$Lex_Dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test assumes normal distributed variables (in both groups). You have the tools to test for the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro.test(aphasiker[aphasiker$Aphasie == \"B\", 14])\n",
    "shapiro.test(aphasiker[aphasiker$Aphasie == \"W\", 14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can test for equal variances across groups. As this assumption holds, we can make our test even more precise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.test(aphasiker_BW$Lex_Dec ~ aphasiker_BW$Aphasie)\n",
    "t.test(aphasiker_BW$Lex_Dec ~ aphasiker_BW$Aphasie, var.equal=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many versions of the t-tests exist. Here are some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-sided t-tests: greater or less\n",
    "t.test(aphasiker_BW$Lex_Dec ~ aphasiker_BW$Aphasie, alternative=\"greater\")  \n",
    "t.test(aphasiker_BW$Lex_Dec ~ aphasiker_BW$Aphasie, alternative=\"less\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test against given mean value\n",
    "t.test(aphasiker$Lex_Dec, mu=1200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired t-test. Note that the formula notation doesn't make much sense here\n",
    "t.test(aphasiker_BW$Syntax, aphasiker_BW$Wortfindung, paired=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, there are many non-parametric alternatives. The most common one is known as the Wilcoxon rank sum test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilcox.test(aphasiker_BW$Lex_Dec ~ aphasiker_BW$Aphasie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise: statistical testing</span> \n",
    "\n",
    "Test the following null-hypotheses:\n",
    "* The gender distribution of this R course today is random\n",
    "* The claims amount (from the claims data set) is normally distributed\n",
    "* The claims amount (from the claims data set) is exponentially distributed. The rate/lambda of an exponential distribution is defined as 1/expected value\n",
    "* There is no difference in the average claim amount between employed and unemployed (from variable employment status). Can the t-test be used? If not, use the non-parametric alternative wilcox.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures and preparation for analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noted that the preparation of the data is one of the most tedious tasks and the standard operations on a data.frame object, like subsetting/filtering or calculation of new variables, not very intuitive. \n",
    "\n",
    "In this section, you will learn some tips and tricks and better understand the most common data structures for statistical analyses.\n",
    "\n",
    "For this, we will introduce the library **dplyr**, which provides \"a grammar of data manipulation\" and is one of the most popular R packages overall: https://dplyr.tidyverse.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First benefit: dplyr comes with a more readable format (if printed to console, no effect on Jupyter notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aphasiker <- tbl_df(aphasiker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aphasiker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class(aphasiker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of quite verbose functions covers the most important data manipulation tasks: \n",
    "* mutate() adds new variables that are functions of existing variables\n",
    "* select() picks variables based on their names.\n",
    "* filter() picks cases based on their values.\n",
    "* summarise() reduces multiple values down to a single summary.\n",
    "* arrange() changes the ordering of the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the **filtering** by rows in base r and dplyr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aphasiker[aphasiker$Aphasie == \"B\" & aphasiker$Alter >= 50, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(aphasiker, Aphasie == \"B\", Alter >= 50) # \"&\" for AND would also work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With **select**, multiple columns can be selected, even without listing each column by name! Instead of contains(), also starts_with(), ends_with() or matches() works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select(aphasiker, Patienten_ID, Aphasie, Lex_Dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select(aphasiker, Patienten_ID:Artikulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select(aphasiker, Patienten_ID, Aphasie, contains(\"Wert\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting data.frames in R is one of the most viewved stack-overflow questions:<br>\n",
    "https://stackoverflow.com/questions/1296646/how-to-sort-a-dataframe-by-columns\n",
    "\n",
    "With dplyr, **arrange** can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrange(aphasiker, Lex_Dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrange(aphasiker, -Artikulation, -Syntax, -Wortfindung)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dplyr is used often together with the **pipe operator (%>%)**. The pipe operator is available, when dplyr is loaded through the package magrittr.<br>\n",
    "The allows to \"chain\" operations instead of nesting them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arrange(filter(select(aphasiker, Patienten_ID, Aphasie, Lex_Dec), Lex_Dec > 1600), -Lex_Dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aphasiker %>%\n",
    "    select(Patienten_ID, Aphasie, Lex_Dec) %>%\n",
    "    filter(Lex_Dec > 1600) %>%\n",
    "    arrange(-Lex_Dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise: data manipulation</span> \n",
    "\n",
    "Get all claims with open complaints and sort by claim amount (descending). Try with and without the pipe operator %>%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With **mutate**, new (calculated) columns can be added to the data.frame. The new or mutated data.frame needs to explicitly stored into (the same) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aphasiker$Lex_Dec_2 <- round(aphasiker$Lex_Dec, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aphasiker <- mutate(aphasiker, Lex_Dec_2 = round(Lex_Dec, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **group_by** to create a grouped copy of the table. All dplyr functions (like summarise) will manipulate each group seperately and the combine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aphasiker_grouped <- group_by(aphasiker, Aphasie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise(aphasiker_grouped, avg_Lex_Dec = mean(Lex_Dec, na.rm=T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise(aphasiker_grouped, \n",
    "          avg_Lex_Dec = mean(Lex_Dec, na.rm=T),\n",
    "          sd_Lex_Dec = sd(Lex_Dec, na.rm=T),\n",
    "          count = n(),\n",
    "          distinct_Syntax = n_distinct(Syntax)\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*n_distinct(vector)* can also be used outside summarise() It is much faster and convinient than than *length(unique(vector))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_distinct(aphasiker$Aphasie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**samples** can be drawn in a convenient way with sample_n (absolute number) or sample_frac (relative). In case the table is grouped, the size of the sample applies to each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_frac(aphasiker_grouped, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics in R: statistical modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic principle of statistical modelling in R consists of the following steps:\n",
    "\n",
    "###### Design your model using the model formulae syntax: \n",
    "lm(y ~ v1 + v2 + scale(v3) + log(v4) + v1*v2 + v1:v2:v3)\n",
    "* y is the dependent variable\n",
    "* v1 to v3 are the independent variables\n",
    "* use ~ to separate the LHS from the RHS\n",
    "* scale() for standardized coefficients or use other transformations like log()\n",
    "* use * to interact variables\n",
    "* use : to interact all possible combinations of the variables\n",
    "\n",
    "###### Relate variables in the formula to your data. The following are equivalent:\n",
    "lm(y ~ v1 + v2, data = data.frame)<br>\n",
    "lm(data.frame[,i] ~ data.frame[,j] + data.frame[,k])<br>\n",
    "\n",
    "###### Save fitted model and obtain summary statistics\n",
    "fit <- lm(y ~ v1 + v2, data = data.frame)<br>\n",
    "summary(fit) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA\n",
    "ANOVA represent statistical approaches frequently used. A simple one-way ANOVA is similar to the t-test, but it allows to test differences in the mean simultaneosly for more than 2 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit <- aov(aphasiker$Lex_Dec ~ aphasiker$Aphasie)\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the results affected by the gender or are there any interaction effects? Let's control for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2 <- aov(aphasiker$Lex_Dec ~ aphasiker$Aphasie + aphasiker$Geschlecht)\n",
    "summary(fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit3 <- aov(aphasiker$Lex_Dec ~ aphasiker$Aphasie + aphasiker$Geschlecht +\n",
    "              aphasiker$Aphasie:aphasiker$Geschlecht)\n",
    "summary(fit3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short form version\n",
    "fit3 <- aov(aphasiker$Lex_Dec ~ aphasiker$Aphasie*aphasiker$Geschlecht)\n",
    "summary(fit3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test for equal variances across more than two group, we can use the Levene Test. This function is implemented in the package \"car\". You might need to install the package first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"car\")\n",
    "library(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leveneTest(aphasiker$Lex_Dec ~ aphasiker$Aphasie*aphasiker$Geschlecht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also non-parametric alternatives to the one-way ANOVA in case of unequal variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneway.test(aphasiker$Lex_Dec ~ aphasiker$Aphasie + aphasiker$Geschlecht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation analyses\n",
    "\n",
    "Correlation analysis can be used to study the relationship between two variables. Pearson's correlation coefficient is frequently used. The parameter \"use\" controls how to handle missing values (see ?cor for details).\n",
    "\n",
    "Often, it also helps to visualize the relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(aphasiker$Alter, aphasiker$Lex_Dec, use=\"complete.obs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(aphasiker$Alter, aphasiker$Lex_Dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also \"test\" the correlation between two variables. The test handels missing values automatically by removing the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test 1: Pearson's cor\n",
    "cor.test(aphasiker$Alter, aphasiker$Lex_Dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Spearman's rho\n",
    "cor.test(aphasiker$Alter, aphasiker$Lex_Dec,\n",
    "         method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Kendall's tau\n",
    "cor.test(aphasiker$Alter, aphasiker$Lex_Dec,\n",
    "         method=\"kendall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise: correlation analyses</span> \n",
    "\n",
    "Are there any correlations between Claim Amount and Total Claim Amount / Months.Since.Policy.Inception / Income?\n",
    "Please use the appropriate statistical correlation tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression modelling\n",
    "Regression models allow to analyse more complex relationships. Linear regression models are the simplest models. First, we write down our model using the formula notation, then we obtain model results via summary()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1 <- lm(Lex_Dec ~ Alter, data=aphasiker)\n",
    "summary(lm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lm2 <- lm(Lex_Dec ~ Aphasie + Geschlecht, data=aphasiker)\n",
    "summary(lm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary object of contains a list of many results of the fitted models. Explore the structure of the summary object with str() or extract specific results such as the adjusted R-squared measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(summary(lm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(lm2)$adj.r.squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are additional functions to calculate metrics on the fitted model, like the AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC(lm1)\n",
    "AIC(lm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important to test the model specification. For instance, OLS assumes normality of the residuals. First, we need to extract the standardized residuals. Then, we can use the ks.test (or alternative tests) or we can draw a historgram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm2_res <- rstandard(lm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks.test(lm2_res, \"pnorm\", mean=mean(lm2_res), sd=sd(lm2_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(lm2_res, breaks=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further standard tests are the test for multicollinearity. Therefore, the VIF (Variance Inflation Factors) is calculated. This test is implemented in the car package. Alternatively, you can draw on the visual model diagnostic plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(car)\n",
    "vif(lm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(lm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced regression modelling\n",
    "\n",
    "Poisson or negative binomial regression for count data:\n",
    "* glm(y ~ v1 + v2 + …, family=\"poisson\")\n",
    "* glm.nb(y ~ v1 + v2 + …)   \n",
    "\n",
    "Logit or Probit regression for binary (dichotomous) data:\n",
    "* glm(y ~ v1 + v2 + …, family=\"binomial\")\n",
    "* glm(y ~ v1 + v2 + …, family=binomial(link=\"probit\"))\n",
    "\n",
    "Gamma regression for skewed continuous data;\n",
    "* glm(y ~ v1 + v2 + …, family=Gamma(link=\"log\"))\n",
    "\n",
    "Spatial regressions are implemented in the packages spatialreg or spdep, panel data regressions in plm, time series in forecast or tseries, state space modelling in KFAS or dlm ...\n",
    "\n",
    "Interested in Machine Learning or Predictive Modelling?\n",
    "https://cran.r-project.org/web/views/MachineLearning.html\n",
    "http://topepo.github.io/caret/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, actuaries in insurance traditionally (before machine learning methods became popular) have modelled claim severity using a glm with gamma link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_claims <- glm(Claim.Amount ~ Monthly.Premium.Auto + Income + Claim.Reason + Coverage, data=claims, family=Gamma(link='log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(fit_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(fit_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?glm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise: discover advanced statistical modelling methods in R</span> \n",
    "\n",
    "Depending on your interest, do one or more of these exercises.\n",
    "\n",
    "1. Improve the model for predicting the claim amount (e.g. by introducing new co-variates).\n",
    "2. Do some non-linear curve fitting. Try to run and understand the codes from these tutorials: http://davetang.org/muse/2013/05/09/on-curve-fitting/ (shows how to estimate a linear model with polynomials) or  http://www.walkingrandomly.com/?p=5254 (shows how to fit a nonlinear least-squares model)\n",
    "3. Read more on ANOVA in R: https://www.statmethods.net/stats/anova.html  or  http://personality-project.org/r/r.guide.html#factoranal\n",
    "4. Go to http://cran.r-project.org/web/views/ and find a package containing your advanced method. Open their reference manuals and (if available) their vignettes. For instance, you could try to run a Neuronal Net with the package nnet by opening the help with ?nnet and reproducing the given example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming in R\n",
    "\n",
    "### <span style=\"color:gold\">Work smart, not hard.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process multiple files\n",
    "\n",
    "In this section you will learn to process several files at once. In our example, you will process 100 text files. You will plot the observed intensities along the X axis in a simple line plot and save it to a file with a name that corresponds to the name of the text file. You will also produce a CSV file containing the mean non-saturated intensities for each file. The input data is in the folder \"Mannobi\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Reading and skipping a few lines\n",
    "# Putting that in a dataframe\n",
    "# Time, title and y values change so focus on those\n",
    "# Variability, % == 999.999, average, plot for each file. How do I write the\n",
    "# outputs to a file now?\n",
    "\n",
    "# Get a list of all files in that directory\n",
    "files <- list.files(\"C:/Users/n351384/OneDrive - Munich Re/Privat/R basics 2days/data/Mannobi\")\n",
    "# Initialize a data frame of mean intensities with 1 row\n",
    "mean.intensities <- data.frame(1)\n",
    "# Loop over all files\n",
    "for (file in files) {\n",
    "  # Read each file, skipping the first 18 lines\n",
    "  read.file <- read.table(file, skip = 18)\n",
    "  # Assume that observations of 999.999 mean that the sensor was oversaturated\n",
    "  read.file$V2[read.file$V2 == 999.999] <- NA\n",
    "  # Construct a file name to save to by concatenating \".png\" to the end of the\n",
    "  # text file's name\n",
    "  filename <- paste(file, \".png\", sep = \"\")\n",
    "  # Open the file as a PNG so you can save the plot to it\n",
    "  png(filename)\n",
    "  # Create the plot from the two columns in the table we read\n",
    "  plot(read.file$V1, read.file$V2,\n",
    "    type = \"l\",  # Plot the observations as a line\n",
    "    xlab = \"Nanometers\",  # Label X axis\n",
    "    ylab = \"Intensity\")  # Label Y axis\n",
    "  dev.off()  # Save and close plot file\n",
    "  # Record mean intensities to the data frame\n",
    "  mean.intensities[[file]] <- mean(read.file$V2, na.rm = TRUE)\n",
    "}\n",
    "# Save the mean intensity data frame to disk\n",
    "write.csv(mean.intensities, \"mean_intensities.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Part 2 (ggplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"ggplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics. You provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.\" (from https://ggplot2.tidyverse.org/).\n",
    "\n",
    "Let's start with a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"ggplot2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p <- ggplot(data=mtcars, aes(factor(cyl), mpg)) + geom_boxplot(aes(fill = cyl))\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph is seen as a structure built from several components:\n",
    "* data\n",
    "* statistical transformation\n",
    "* coordinate system\n",
    "* geometric object\n",
    "* scales\n",
    "* faceting / position adjustments\n",
    "\n",
    "For example, a *histogram* is composed of bars (=geometric object), in which the data is binned (=statistical transformation) and the height is on a linear scale (=scales). \n",
    "\n",
    "Likewise, a *scatterplot* is composed of points (=geometric object) in which the original data is not further statistically transformed. \n",
    "\n",
    "**Key features:**\n",
    "* ggplot creates a plot sequentially via multiple layers - use \"+\" to add a layer\n",
    "* the aesthetics argument aes(x,y, …) dictates the role of the variables, i.e. how they are visually represented\n",
    "* grouping is achieved by assigning a factor variable to a color, shape or fill aesthetic\n",
    "* many geometric objects (geoms) have an implicit stat component, e.g. geom_smooth = geom_ribbon + stat_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the coverages in the claims data set can be visualized using a bar-chart. Grouping the bars (e.g. by filling it conditional to another variable) allows to display additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(claims, aes(x=Coverage)) +\n",
    "  geom_bar(stat=\"count\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(claims, aes(x=Coverage, fill=Education)) +\n",
    "  geom_bar(stat=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(claims, aes(x=Coverage, fill=Education)) +\n",
    "  geom_bar(position=\"dodge\", stat=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you simply change the coordinate system from cartesian to polar, the bar chart becomes a rose chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(claims, aes(x=Vehicle.Class, fill=Education)) +\n",
    "  geom_bar(stat=\"count\", width = 0.9) + \n",
    "  coord_polar(theta = \"y\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms or scatterplots are frequently used chart types. See the official reference for an overview on available components (geoms, scales etc.):<br>\n",
    "https://ggplot2.tidyverse.org/reference/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(claims, aes(x=Claim.Amount)) +\n",
    "  geom_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(claims, aes(x=Claim.Amount)) +\n",
    "  geom_histogram(stat=\"bin\", binwidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(claims, aes(x=Monthly.Premium.Auto, y=Claim.Amount)) +\n",
    "  geom_point() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots can be customized by adding and modifying the components. Colors are usually defined via fill/ colour scales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(claims, aes(x=Monthly.Premium.Auto, y=Claim.Amount)) +\n",
    "  geom_point(color=\"darkblue\", size=0.5, alpha=0.3) +\n",
    "  theme_bw() +\n",
    "  labs(title=\"Claim Analyses\", x=\"Monthly Premium\", y=\"Claim Amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(claims, aes(x=Monthly.Premium.Auto, y=Claim.Amount, color=Coverage)) +\n",
    "  geom_point(size=0.5, alpha=0.3) +\n",
    "  scale_colour_brewer(palette = \"Set1\") +\n",
    "  labs(title=\"Claim Analyses\", x=\"Monthly Premium\", y=\"Claim Amount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facetting allows to \"break down\" a plot into various sub-plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... facetting by coverage and adding a regression line\n",
    "ggplot(claims, aes(x=Monthly.Premium.Auto, y=Claim.Amount, color=Coverage)) +\n",
    "  geom_point(size=0.5,alpha=0.3) +\n",
    "  facet_wrap(~Coverage) +\n",
    "  geom_smooth(method=\"lm\", color=\"orange\", linetype=2) +\n",
    "  labs(title=\"Claim Analyses\", x=\"Monthly Premium\", y=\"Claim Amount\") +\n",
    "  scale_colour_brewer(palette = \"Set1\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise: create your first ggplot of your own</span> \n",
    "\n",
    "Consult the ggplot2 references for insporation and guidance: https://ggplot2.tidyverse.org/reference/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for an alternative tutorial on ggplot2?\n",
    "* Tutorial 1: http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html\n",
    "* Tutorial 2: http://r-statistics.co/Complete-Ggplot2-Tutorial-Part1-With-R-Code.html\n",
    "\n",
    "Looking for inspiration:\n",
    "* https://www.r-graph-gallery.com/\n",
    "* http://www.ggplot2-exts.org/gallery/\n",
    "\n",
    "Looking for interactive charts:\n",
    "* plotly: https://plot.ly/r/\n",
    "* R Shiny: https://shiny.rstudio.com/\n",
    "* Leaflet: https://rstudio.github.io/leaflet/\n",
    "\n",
    "Find beautiful colors:\n",
    "* http://colorbrewer2.org/ or package RColorBrewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducible research in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
